{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-rag-lab/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 1: Setup prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -Uq pandas datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pymongo import MongoClient\n",
        "from utils import track_progress\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 150)\n",
        "\n",
        "from datasets import load_dataset\n",
        "from typing import Dict, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you are using your own MongoDB Atlas cluster, use the connection string for your cluster here\n",
        "MONGODB_URI = os.environ.get(\"MONGODB_URI\")\n",
        "# Initialize a MongoDB Python client\n",
        "mongodb_client = MongoClient(MONGODB_URI)\n",
        "# Check the connection to the server\n",
        "mongodb_client.admin.command(\"ping\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track progress of key steps-- DO NOT CHANGE\n",
        "track_progress(\"cluster_creation\", \"primary_care_assistant_lab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVERLESS_URL = os.environ.get(\"SERVERLESS_URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define database and collection names\n",
        "DB_NAME = \"virtual_primary_care_assistant\"\n",
        "DRUG_REVIEW_COLLECTION_NAME = \"drug_reviews\"\n",
        "\n",
        "# Get a reference to the database (creates it if it doesn't exist)\n",
        "db = mongodb_client[DB_NAME]\n",
        "\n",
        "# Get a reference to collections for later use\n",
        "drug_reviews_collection = db[DRUG_REVIEW_COLLECTION_NAME]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2: Load drug reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the drug reviews dataset from Hugging Face repository\n",
        "# This dataset contains patient reviews of various medications\n",
        "# 'Reboot87/drugs_reviews_dataset' contains structured data about drug experiences\n",
        "drug_reviews_dataset = load_dataset(\n",
        "    \"Reboot87/drugs_reviews_dataset\", streaming=True, split=\"train\"\n",
        ")\n",
        "\n",
        "# Limit the dataset to 10,000 examples to manage memory usage and processing time\n",
        "# This sample size should be sufficient for building our demonstration model\n",
        "# The streaming=True parameter ensures we don't load the entire dataset into memory\n",
        "drug_reviews_dataset = drug_reviews_dataset.take(1000)\n",
        "\n",
        "# Similarly convert the drug reviews dataset to a DataFrame\n",
        "# This enables SQL-like operations, filtering, and statistical analysis\n",
        "# Having both datasets as DataFrames ensures consistent data handling approaches\n",
        "drug_reviews_dataset = pd.DataFrame(drug_reviews_dataset)\n",
        "\n",
        "# Remove the attributes patientId, date, usefulCount and review_length from the drug_reviews_dataset\n",
        "# patientId: Removed to ensure data anonymization and privacy protection\n",
        "# date: Temporal information isn't critical for our current analysis\n",
        "# usefulCount: Engagement metrics aren't relevant for our semantic understanding\n",
        "# review_length: This is a derived feature that can be recalculated if needed\n",
        "drug_reviews_dataset = drug_reviews_dataset.drop(\n",
        "    columns=[\"patientId\", \"date\", \"usefulCount\", \"review_length\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview a document to understand its structure\n",
        "drug_reviews_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete existing records\n",
        "drug_reviews_collection.delete_many({});\n",
        "\n",
        "# Insert new records\n",
        "drug_reviews_dataset = drug_reviews_dataset.to_dict(\"records\")\n",
        "\n",
        "#<CODE_BLOCK_1>\n",
        "drug_reviews_collection.insert_many(drug_reviews_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Implement search on drug reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a search index\n",
        "\n",
        "📚 https://www.mongodb.com/docs/atlas/atlas-search/define-field-mappings/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the text search index definition for the drugs_review dataset.\n",
        "# This configuration specifies that only the \"drugName\" and \"condition\" fields will be indexed,\n",
        "# and automatic field detection is disabled.\n",
        "DRUG_REVIEW_SEARCH_INDEX_NAME='drug_review_search_index'\n",
        "\n",
        "drug_review_text_search_model = {\n",
        "    \"name\": DRUG_REVIEW_SEARCH_INDEX_NAME,\n",
        "    \"type\": \"search\",\n",
        "    \"definition\": {\n",
        "        \"analyzer\": \"lucene.english\",\n",
        "        \"mappings\": {\n",
        "            \"dynamic\": False,  # Disable automatic detection; only explicitly defined fields are indexed.\n",
        "            #<CODE_BLOCK_2>\n",
        "            \"fields\": {\n",
        "                \"drugName\": {\n",
        "                    \"type\": \"string\"\n",
        "                },  # Index the \"drugName\" field as searchable text.\n",
        "                \"condition\": {\n",
        "                    \"type\": \"string\"\n",
        "                },  # Index the \"condition\" field as searchable text.\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create search index\n",
        "# <CODE_BLOCK_3>\n",
        "drug_reviews_collection.create_search_index(drug_review_text_search_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perform text search\n",
        "\n",
        "📚 https://www.mongodb.com/docs/atlas/atlas-search/aggregation-stages/search/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definition to perform text search\n",
        "def drug_review_text_search(query_text):\n",
        "    \"\"\"\n",
        "    Perform a text search in the MongoDB collection based on the user query.\n",
        "\n",
        "    Args:\n",
        "        query_text (str): The user's query string.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of matching documents.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the text search stage using MongoDB's $search operator.\n",
        "    # This is part of Atlas Search and provides more powerful text search capabilities\n",
        "    # than MongoDB's standard text index.\n",
        "    # Perform a text search on the paths \"drugName\" and condition.\n",
        "    # Cater for typo tolerance with 2 maxEdits.\n",
        "    text_search_stage = {\n",
        "        \"$search\": {\n",
        "            \"index\": DRUG_REVIEW_SEARCH_INDEX_NAME,\n",
        "            #<CODE_BLOCK_4>\n",
        "            \"text\": {\n",
        "                \"query\": query_text,  # The actual search term provided by the user.\n",
        "                \"path\": [\"drugName\",\"condition\"], \n",
        "                \"fuzzy\": {\n",
        "                    \"maxEdits\": 2\n",
        "                }\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Limit the number of results returned to improve performance.\n",
        "    # This is especially important for large collections.\n",
        "    limit_stage = {\"$limit\": 5}\n",
        "\n",
        "    # Define which fields to include in the returned documents.\n",
        "    # Excluding unnecessary fields reduces bandwidth and processing overhead.\n",
        "    project_stage = {\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,  # Exclude MongoDB's internal ID field.\n",
        "            \"embedding\": 0,  # Exclude the embedding field.\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Combine all stages into a MongoDB aggregation pipeline.\n",
        "    # The pipeline will execute stages in sequence: search, limit, then project.\n",
        "    pipeline = [text_search_stage, limit_stage, project_stage]\n",
        "\n",
        "    # Execute the search by running the aggregation pipeline against the specified collection.\n",
        "    # Convert the cursor to a list to ensure results are fully fetched before the function returns.\n",
        "    #results = <CODE_BLOCK_5>\n",
        "    results = drug_reviews_collection.aggregate(pipeline)\n",
        "\n",
        "    return list(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_results = drug_review_text_search(\"I am coughing\")\n",
        "pd.DataFrame(temp_results).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test our text search by mispelling dextromethorphan\n",
        "temp_results = drug_review_text_search(\"How is dextormethorphan\")\n",
        "\n",
        "# notice the false positives\n",
        "pd.DataFrame(temp_results).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4: Generate embeddings on drug reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You may see a warning upon running this cell. You can ignore it.\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the `gte-small` model using the Sentence Transformers library\n",
        "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "📚 https://huggingface.co/thenlper/gte-small#usage (See \"Use with sentence-transformers\" under Usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function that takes a piece of text (`text`) as input, embeds it using the `embedding_model` instantiated above and returns the embedding as a list\n",
        "# An array can be converted to a list using the `tolist()` method\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    \"\"\"\n",
        "    Generate the embedding for a piece of text.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to embed.\n",
        "\n",
        "    Returns:\n",
        "        List[float]: Embedding of the text as a list.\n",
        "    \"\"\"\n",
        "    #embedding = <CODE_BLOCK_6>\n",
        "    embedding = embedding_model.encode(text)\n",
        "    return embedding.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedded_docs = []\n",
        "# Add an `embedding` field to each dictionary in `drug_reviews_dataset`\n",
        "# The `embedding` field should correspond to the embedding of the value of the `review` field\n",
        "# Use the `get_embedding` function defined above to generate the embedding\n",
        "# Append the updated dictionaries to `embedded_docs` initialized above.\n",
        "for doc in tqdm(drug_reviews_dataset):\n",
        "\n",
        "    # format doc to proper sentence\n",
        "    record = (\n",
        "        f\"Drug Name: {doc['drugName']}. \"\n",
        "        f\"Condition: {doc['condition']}. \"\n",
        "        f\"Review: {doc['review']}.\"\n",
        "    )\n",
        "    # <CODE_BLOCK_7>\n",
        "    doc['embedding'] = get_embedding(record)\n",
        "    embedded_docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check that the length of `embedded_docs` should be same as the dataset\n",
        "len(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 5: Re-ingest data into MongoDB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drug_reviews_collection.delete_many({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bulk insert `embedded_docs` into the `collection` defined above -- should be a one-liner\n",
        "drug_reviews_collection.insert_many(embedded_docs)\n",
        "print(f\"Ingested {drug_reviews_collection.count_documents({})} documents into the {DRUG_REVIEW_COLLECTION_NAME} collection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 6: Implement vector search capability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a vector search index\n",
        "\n",
        "📚 https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create vector index definition specifying:\n",
        "# path: Path to the embeddings field\n",
        "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
        "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
        "DRUG_REVIEW_VECTOR_SEARCH_INDEX_NAME='drug_review_vector_search_index'\n",
        "\n",
        "drug_review_vector_search_model = {\n",
        "    \"name\": DRUG_REVIEW_VECTOR_SEARCH_INDEX_NAME,\n",
        "    \"type\": \"vectorSearch\",\n",
        "    \"definition\": {\n",
        "        \"fields\": [\n",
        "            # Define a vector field on the path \"embedding\"\n",
        "            # It has 384 dimensions and uses the cosine similarity\n",
        "            # <CODE_BLOCK_8>\n",
        "            {\n",
        "                \"type\": \"vector\",\n",
        "                \"path\": \"embedding\",\n",
        "                \"numDimensions\": 384,\n",
        "                \"similarity\": \"cosine\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create vector search index\n",
        "# <CODE_BLOCK_9>\n",
        "drug_reviews_collection.create_search_index(drug_review_vector_search_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the `check_index_ready` function from the `utils` module to verify that the index was created and is in READY status before proceeding\n",
        "from utils import check_index_ready\n",
        "check_index_ready(drug_reviews_collection, DRUG_REVIEW_VECTOR_SEARCH_INDEX_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track progress of key steps-- DO NOT CHANGE\n",
        "track_progress(\"vs_index_creation\", \"primary_care_assistant_lab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a vector search function\n",
        "\n",
        "📚 https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to retrieve relevant documents for a user query using vector search\n",
        "def drug_review_vector_search(user_query: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Retrieve relevant documents for a user query using vector search.\n",
        "\n",
        "    Args:\n",
        "    user_query (str): The user's query string.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of matching documents.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate embedding for the `user_query` using the `get_embedding` function defined in Step 4\n",
        "    query_embedding = get_embedding(user_query)\n",
        "\n",
        "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
        "    # Set the number of candidates to 50 and only return the top 5 documents from the vector search\n",
        "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
        "    pipeline = [\n",
        "    {\n",
        "        #vector search stage\n",
        "        #<CODE_BLOCK_10>\n",
        "        \"$vectorSearch\": {\n",
        "            \"index\": DRUG_REVIEW_VECTOR_SEARCH_INDEX_NAME,\n",
        "            \"queryVector\": query_embedding,\n",
        "            \"path\": \"embedding\",\n",
        "            \"numCandidates\": 50,\n",
        "            \"limit\": 5\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"$project\": {\n",
        "            \"_id\": 0,\n",
        "            \"embedding\": 0,\n",
        "            \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "    # Execute the aggregation `pipeline` and store the results in `results`\n",
        "    results = drug_reviews_collection.aggregate(pipeline)\n",
        "    return list(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run vector search queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_results = drug_review_vector_search(\"How is dextromethorphan\")\n",
        "\n",
        "pd.DataFrame(temp_results).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 7: Implementing hybrid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hybrid_search(\n",
        "    text_search_query,\n",
        "    vector_search_query,\n",
        "    vector_weight=0.5,\n",
        "    full_text_weight=0.5,\n",
        "    top_k=10,\n",
        "    text_search_paths=[\"drugName\",\"condition\"],\n",
        "):\n",
        "    \"\"\"\n",
        "    Conduct a hybrid search on a MongoDB Atlas collection that combines a vector search\n",
        "    and a full-text search using Atlas Search.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's query string.\n",
        "        collection (MongoCollection): The MongoDB collection to search.\n",
        "        vector_search_index_name (str): The name of the vector search index.\n",
        "        text_search_index_name (str): The name of the text search index.\n",
        "        vector_weight (float): The weight of the vector search.\n",
        "        full_text_weight (float): The weight of the full-text search.\n",
        "        top_k (int): Number of results to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of documents (dict) with combined scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the pre-computed embedding vector for the user's query\n",
        "    query_vector = get_embedding(vector_search_query)\n",
        "\n",
        "    # Create a MongoDB aggregation pipeline to perform hybrid search\n",
        "    pipeline = [\n",
        "        # PART 1: VECTOR SEARCH\n",
        "        # Perform semantic vector search using the query embedding\n",
        "        {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": DRUG_REVIEW_VECTOR_SEARCH_INDEX_NAME,  # Name of the vector search index\n",
        "                \"path\": \"embedding\",  # Field containing document embeddings\n",
        "                \"queryVector\": query_vector,  # The query vector to compare against\n",
        "                \"numCandidates\": top_k*10,  # Number of candidates to consider for similarity\n",
        "                \"limit\": top_k,  # Initial limit of results\n",
        "            }\n",
        "        },\n",
        "        # Group all vector search results into a single document\n",
        "        # This prepares for the ranking step\n",
        "        {\n",
        "            \"$group\": {\n",
        "                \"_id\": None,\n",
        "                \"docs\": {\"$push\": \"$$ROOT\"},  # Push all documents into an array\n",
        "            }\n",
        "        },\n",
        "        # Unwind the array of documents to process each individually\n",
        "        # This adds a rank based on the original vector search order\n",
        "        {\n",
        "            \"$unwind\": {\n",
        "                \"path\": \"$docs\",\n",
        "                \"includeArrayIndex\": \"rank\",  # Add the array index as a rank field\n",
        "            }\n",
        "        },\n",
        "        # Calculate a vector search score based on rank\n",
        "        # Higher ranks get lower scores via division formula\n",
        "        {\n",
        "            \"$addFields\": {\n",
        "                \"vs_score\": {\n",
        "                    \"$multiply\": [\n",
        "                        vector_weight,  # Apply configurable weight to vector scores\n",
        "                        {\n",
        "                            \"$divide\": [1.0, {\"$add\": [\"$rank\", 60]}]\n",
        "                        },  # Score formula: 1/(rank+60)\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        # Project only the needed fields from each document\n",
        "        # Including the calculated vector search score\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"vs_score\": 1,\n",
        "                \"_id\": \"$docs._id\",\n",
        "                \"review\": \"$docs.review\",\n",
        "                \"drugName\": \"$docs.drugName\",\n",
        "                \"condition\": \"$docs.condition\",\n",
        "            }\n",
        "        },\n",
        "        # PART 2: TEXT SEARCH\n",
        "        # Combine with full-text search results using unionWith\n",
        "        {\n",
        "            \"$unionWith\": {\n",
        "                \"coll\": DRUG_REVIEW_COLLECTION_NAME,  # Collection to search\n",
        "                \"pipeline\": [\n",
        "                    # Perform full text search using Atlas Search\n",
        "                    {\n",
        "                        \"$search\": {\n",
        "                            \"index\": DRUG_REVIEW_SEARCH_INDEX_NAME,  # Name of the text search index\n",
        "                            \"text\": {\n",
        "                                \"query\": text_search_query,  # Raw text query from user\n",
        "                                \"path\": text_search_paths,  # Field to search in\n",
        "                                \"fuzzy\": {\n",
        "                                     \"maxEdits\": 2\n",
        "                                }\n",
        "                            },\n",
        "                        }\n",
        "                    },\n",
        "                    {\"$limit\": top_k},  # Limit initial text search results\n",
        "                    # Group text search results similar to vector search\n",
        "                    {\"$group\": {\"_id\": None, \"docs\": {\"$push\": \"$$ROOT\"}}},\n",
        "                    # Unwind and add ranking just like in vector search\n",
        "                    {\"$unwind\": {\"path\": \"$docs\", \"includeArrayIndex\": \"rank\"}},\n",
        "                    # Calculate a full-text search score based on rank\n",
        "                    # Using the same formula as vector search\n",
        "                    {\n",
        "                        \"$addFields\": {\n",
        "                            \"fts_score\": {\n",
        "                                \"$multiply\": [\n",
        "                                    full_text_weight,  # Apply configurable weight to text scores\n",
        "                                    {\"$divide\": [1.0, {\"$add\": [\"$rank\", 60]}]},\n",
        "                                ]\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    # Project only the needed fields for text search results\n",
        "                    {\n",
        "                        \"$project\": {\n",
        "                            \"fts_score\": 1,\n",
        "                            \"_id\": \"$docs._id\",\n",
        "                            \"review\": \"$docs.review\",\n",
        "                            \"drugName\": \"$docs.drugName\",\n",
        "                            \"condition\": \"$docs.condition\",\n",
        "                        }\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        },\n",
        "        # PART 3: COMBINING RESULTS\n",
        "        # Group by document ID to handle duplicates from both searches\n",
        "        # This ensures we don't return the same document twice\n",
        "        {\n",
        "            \"$group\": {\n",
        "                \"_id\": \"$_id\",\n",
        "                \"review\": {\"$first\": \"$review\"},\n",
        "                \"drugName\": {\"$first\": \"$drugName\"},\n",
        "                \"condition\": {\"$first\": \"$condition\"},\n",
        "                \"vs_score\": {\n",
        "                    \"$max\": \"$vs_score\"\n",
        "                },  # Take highest vector score if present in both\n",
        "                \"fts_score\": {\n",
        "                    \"$max\": \"$fts_score\"\n",
        "                },  # Take highest text score if present in both\n",
        "            }\n",
        "        },\n",
        "        # Handle documents that only appeared in one search type\n",
        "        # by setting missing scores to 0\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"_id\": 1,\n",
        "                \"review\": 1,\n",
        "                \"drugName\": 1,\n",
        "                \"condition\": 1,\n",
        "                \"vs_score\": {\n",
        "                    \"$ifNull\": [\"$vs_score\", 0]\n",
        "                },  # Default to 0 if not in vector results\n",
        "                \"fts_score\": {\n",
        "                    \"$ifNull\": [\"$fts_score\", 0]\n",
        "                },  # Default to 0 if not in text results\n",
        "            }\n",
        "        },\n",
        "        # Calculate the final combined score and remove _id from results\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"score\": {\"$add\": [\"$fts_score\", \"$vs_score\"]},  # Combined final score\n",
        "                \"_id\": 0,  # Exclude MongoDB ID\n",
        "                \"review\": 1,\n",
        "                \"drugName\": 1,\n",
        "                \"condition\": 1,\n",
        "                \"vs_score\": 1,  # Keep individual scores for analysis\n",
        "                \"fts_score\": 1,\n",
        "            }\n",
        "        },\n",
        "        # Sort by the combined score in descending order\n",
        "        {\"$sort\": {\"score\": -1}},\n",
        "        # Return only the top k results based on combined score\n",
        "        {\"$limit\": top_k},\n",
        "    ]\n",
        "\n",
        "    # Execute the aggregation pipeline and convert results to a list\n",
        "    results = list(drug_reviews_collection.aggregate(pipeline))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# query_text = \"I have a cough, what drug would be best?\"\n",
        "query_text = \"How is dextromethorphan?\"\n",
        "\n",
        "# Execute a hybrid search that combines both vector (semantic) and full-text search\n",
        "# We can change the weightage if necessary\n",
        "\n",
        "drug_reviews_hybrid_results = hybrid_search(\n",
        "    query_text,  # Our natural language query\n",
        "    query_text\n",
        ")\n",
        "\n",
        "pd.DataFrame(drug_reviews_hybrid_results).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 8: Build the RAG application\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a function to create the chat prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_context(context) -> str:\n",
        "    formatted_context = \"\"\n",
        "\n",
        "    # Check if any documents were retrieved.\n",
        "    if context and len(context) > 0:\n",
        "        # Add a header for the context section.\n",
        "        formatted_context = \"\\n\\nRelevant information from drug reviews:\\n\\n\"\n",
        "\n",
        "        # Process each retrieved document and format its content.\n",
        "        for i, doc in enumerate(context):\n",
        "            # Extract key fields from the document.\n",
        "            review = doc.get(\"review\", \"No review available\")\n",
        "            condition = doc.get(\"condition\", \"No condition available\")\n",
        "            drug_name = doc.get(\"drugName\", \"No drug name available\")\n",
        "\n",
        "            # Append the formatted document with a citation reference.\n",
        "            formatted_context += f\"[{i+1}] Review: {review}\\nCondition: {condition}\\nDrug Name: {drug_name}\\n\\n\"\n",
        "    return formatted_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to create the user prompt for our RAG application\n",
        "def create_prompt(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Create a chat prompt that includes the user query and retrieved context.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's query string.\n",
        "\n",
        "    Returns:\n",
        "        str: The chat prompt string.\n",
        "    \"\"\"\n",
        "    # Retrieve the most relevant documents for the `user_query` using the `vector_search` function defined in Step 7\n",
        "    context = hybrid_search(user_query,user_query)\n",
        "    # 1. Join the retrieved documents into a single string, where each document is separated by two new lines (\"\\n\\n\")\n",
        "    # 2. Format the retrieved documents into context for the LLM.\n",
        "    #formatted_context = <CODE_BLOCK_11>\n",
        "    formatted_context = format_context(context)\n",
        "\n",
        "    # 3. Craft the prompt for the LLM using the user query and the formatted context.\n",
        "    prompt = f\"\"\"\n",
        "Based on the following information, please answer the user's question:\n",
        "User Question: {user_query}\n",
        "{formatted_context}\n",
        "Please provide a comprehensive answer based on the information above.\n",
        "If the provided information does not contain the answer, state that clearly.\n",
        "Include citation numbers [X] to indicate which sources were used for specific details.\n",
        "\"\"\"\n",
        "\n",
        "    # Prompt consisting of the question and relevant context to answer it\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a function to answer user queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to answer user queries\n",
        "def generate_answer(user_query: str) -> None:\n",
        "    \"\"\"\n",
        "    Generate an answer to the user query.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's query string.\n",
        "    \"\"\"\n",
        "    # Use the `create_prompt` function above to create a chat prompt\n",
        "    prompt = create_prompt(user_query)\n",
        "    # Format the message to the LLM in the format [{\"role\": <role_value>, \"content\": <content_value>}\n",
        "    # The role value for user messages must be \"user\"\n",
        "    # Use the `prompt` created above to populate the `content` field in the chat message\n",
        "    #messages = <CODE_BLOCK_12>\n",
        "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "    # Send the chat messages to a serverless function to get back an LLM response\n",
        "    response = requests.post(url=SERVERLESS_URL, json={\"task\": \"completion\", \"data\": messages})\n",
        "    # Print the final answer\n",
        "    print(response.json()[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query the RAG application\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_text = \"I have a cough, what drug would be best?\"\n",
        "#query_text = \"How is dextromethorphan?\"\n",
        "\n",
        "generate_answer(query_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🦹‍♀️ \"Agentic\" Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use LLM to filter out terms that are medical conditions, symptoms, or drug names\n",
        "def get_terms_from_query(user_query: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "        For the following query, return me only words associated with medical conditions, symptoms or drug names: {user_query}.\n",
        "        Respond only with the words, space separated.\n",
        "        \"\"\"\n",
        "\n",
        "    messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "    # Send the chat messages to a serverless function to get back an LLM response\n",
        "    \n",
        "    response = requests.post(url=SERVERLESS_URL, json={\"task\": \"completion\", \"data\": messages})\n",
        "    return response.json()[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test the definition\n",
        "get_terms_from_query(\"I have cough and sore throat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_medication_reviews(user_query:str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves patient reviews and information about medications related to the query.\n",
        "\n",
        "    This tool searches a database of medication reviews to find relevant patient experiences\n",
        "    with drugs that match the symptoms, conditions, or medication names in the user query.\n",
        "    Use this tool when discussing specific medications or treatment options.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The medication name, condition, or symptom to search for reviews about.\n",
        "\n",
        "    Returns:\n",
        "        str: Patient reviews and experiences with relevant medications.\n",
        "    \"\"\"\n",
        "    \n",
        "    refined_text_search_query = get_terms_from_query(user_query)\n",
        "    \n",
        "   # Execute the hybrid search to find medication reviews\n",
        "    retrieved_context = hybrid_search(\n",
        "        refined_text_search_query,\n",
        "        user_query,\n",
        "    )\n",
        "\n",
        "    return retrieved_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "temp_results = get_medication_reviews(\"I have a cought and sore throat, what is best for me\")\n",
        "\n",
        "pd.DataFrame(temp_results).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to create the user prompt for our RAG application\n",
        "def create_prompt(user_query: str) -> str:\n",
        "    \"\"\"\n",
        "    Create a chat prompt that includes the user query and retrieved context.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's query string.\n",
        "\n",
        "    Returns:\n",
        "        str: The chat prompt string.\n",
        "    \"\"\"\n",
        "    # Retrieve the most relevant documents for the `user_query` using the `vector_search` function defined in Step 7\n",
        "    context = get_medication_reviews(user_query)\n",
        "    # Join the retrieved documents into a single string, where each document is separated by two new lines (\"\\n\\n\")\n",
        "        # 2. Format the retrieved documents into context for the LLM.\n",
        "    formatted_context = format_context(context)\n",
        "\n",
        "    # 3. Craft the prompt for the LLM using the user query and the formatted context.\n",
        "    prompt = f\"\"\"\n",
        "Based on the following information, please answer the user's question:\n",
        "User Question: {user_query}\n",
        "{formatted_context}\n",
        "Please provide a comprehensive answer based on the information above.\n",
        "If the provided information does not contain the answer, state that clearly.\n",
        "Include citation numbers [X] to indicate which sources were used for specific details.\n",
        "\"\"\"\n",
        "\n",
        "    # Prompt consisting of the question and relevant context to answer it\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use this if you have not completed \"adding memory\"\n",
        "# generate_answer(\"I have a flu\")\n",
        "\n",
        "# Use this if you have completed \"adding memory\"\n",
        "generate_answer(\"session\", \"I have a flu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 9: Add memory to the RAG application\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_collection = mongodb_client[DB_NAME][\"chat_history\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.create_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an index on the key `session_id` for the `history_collection` collection\n",
        "history_collection.create_index(\"session_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a function to store chat messages in MongoDB\n",
        "\n",
        "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.insert_one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_chat_message(session_id: str, role: str, content: str) -> None:\n",
        "    \"\"\"\n",
        "    Store a chat message in a MongoDB collection.\n",
        "\n",
        "    Args:\n",
        "        session_id (str): Session ID of the message.\n",
        "        role (str): Role for the message. One of `system`, `user` or `assistant`.\n",
        "        content (str): Content of the message.\n",
        "    \"\"\"\n",
        "    # Create a message object with `session_id`, `role`, `content` and `timestamp` fields\n",
        "    # `timestamp` should be set the current timestamp\n",
        "    message = {\n",
        "        \"session_id\": session_id,\n",
        "        \"role\": role,\n",
        "        \"content\": content,\n",
        "        \"timestamp\": datetime.now(),\n",
        "    }\n",
        "    # Insert the `message` into the `history_collection` collection\n",
        "    history_collection.insert_one(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define a function to retrieve chat history from MongoDB\n",
        "\n",
        "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/cursor.html#pymongo.cursor.Cursor.sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_session_history(session_id: str) -> List:\n",
        "    \"\"\"\n",
        "    Retrieve chat message history for a particular session.\n",
        "\n",
        "    Args:\n",
        "        session_id (str): Session ID to retrieve chat message history for.\n",
        "\n",
        "    Returns:\n",
        "        List: List of chat messages.\n",
        "    \"\"\"\n",
        "    # Query the `history_collection` collection for documents where the \"session_id\" field has the value of the input `session_id`\n",
        "    # Sort the results in increasing order of the values in `timestamp` field\n",
        "    cursor = history_collection.find({\"session_id\": session_id}).sort(\"timestamp\", 1)\n",
        "\n",
        "    if cursor:\n",
        "        # Iterate through the cursor and extract the `role` and `content` field from each entry\n",
        "        # Then format each entry as: {\"role\": <role_value>, \"content\": <content_value>}\n",
        "        messages = [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in cursor]\n",
        "    else:\n",
        "        # If cursor is empty, return an empty list\n",
        "        messages = []\n",
        "\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handle chat history in the `generate_answer` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_answer(session_id: str, user_query: str) -> None:\n",
        "    \"\"\"\n",
        "    Generate an answer to the user's query taking chat history into account.\n",
        "\n",
        "    Args:\n",
        "        session_id (str): Session ID to retrieve chat history for.\n",
        "        user_query (str): The user's query string.\n",
        "    \"\"\"\n",
        "    # Initialize list of messages to pass to the chat completion model\n",
        "    messages = []\n",
        "\n",
        "    # Retrieve documents relevant to the user query and convert them to a single string\n",
        "    prompt = create_prompt(user_query)\n",
        "    # Create a system prompt containing the retrieved context\n",
        "    system_message = {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "    # Append the system prompt to the `messages` list\n",
        "    messages.append(system_message)\n",
        "\n",
        "    # Use the `retrieve_session_history` function to retrieve message history from MongoDB for the session ID `session_id` \n",
        "    # And add all messages in the message history to the `messages` list \n",
        "    message_history = retrieve_session_history(session_id)\n",
        "    messages.extend(message_history)\n",
        "\n",
        "    # Format the user query in the format {\"role\": <role_value>, \"content\": <content_value>}\n",
        "    # The role value for user messages must be \"user\"\n",
        "    # And append the user message to the `messages` list\n",
        "    user_message = {\"role\": \"user\", \"content\": user_query}\n",
        "    messages.append(user_message)\n",
        "\n",
        "    # Send the chat messages to a serverless function to get back an LLM response\n",
        "    response = requests.post(url=SERVERLESS_URL, json={\"task\": \"completion\", \"data\": messages})\n",
        "\n",
        "    # Extract the answer from the response\n",
        "    answer = response.json()[\"text\"]\n",
        "\n",
        "    # Use the `store_chat_message` function to store the user message and also the generated answer in the message history collection\n",
        "    # The role value for user messages is \"user\", and \"assistant\" for the generated answer\n",
        "    store_chat_message(session_id, \"user\", user_query)\n",
        "    store_chat_message(session_id, \"assistant\", answer)\n",
        "\n",
        "    print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_answer(\n",
        "    session_id=\"1\",\n",
        "    user_query=\"I have a sore throat\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_answer(\n",
        "    session_id=\"1\",\n",
        "    user_query=\"What if i have a cough too\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
